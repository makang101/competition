{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import os.path\n",
    "OUTPUT_DIR = 'D:\\Project\\pic_dir_processed'\n",
    "INPUT_DIR = 'D:\\Project\\pic_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_pic(filename):\n",
    "    #filename = 'AMxx0001002aa01c.png'\n",
    "    image = cv2.imread(filename)\n",
    "    #print(filename, image)\n",
    "    size = image.shape\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # print(gray)\n",
    "    # cv.namedWindow('image', cv.WINDOW_NORMAL)\n",
    "    # cv.imshow('image', image)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    # cv.imwrite('messigray.png',gray)\n",
    "    gradX = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "    gradY = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "\n",
    "    # subtract the y-gradient from the x-gradient\n",
    "    gradient = cv2.subtract(gradX, gradY)\n",
    "    gradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "    # blur and threshold the image\n",
    "    blurred = cv2.blur(gradient, (9, 9))\n",
    "    (_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # perform a series of erosions and dilations\n",
    "    closed = cv2.erode(closed, None, iterations=4)\n",
    "    closed = cv2.dilate(closed, None, iterations=4)\n",
    "\n",
    "    #(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (_, cnts, whatever1)= cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(len(ans))\n",
    "    # print(ans[0])\n",
    "    # print(ans[1])\n",
    "    # print(ans[2])\n",
    "    c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "    # compute the rotated bounding box of the largest contour\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "\n",
    "    # draw a bounding box arounded the detected barcode and display the image\n",
    "    #cv2.drawContours(image, [box], -1, (0, 255, 0), 3)\n",
    "    #cv2.imshow(\"Image\", image)\n",
    "    #cv2.imwrite(\"contoursImage2.jpg\", image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    Xs = [i[0] for i in box]\n",
    "    Ys = [i[1] for i in box]\n",
    "    x1 = min(Xs)\n",
    "    x2 = max(Xs)\n",
    "    y1 = min(Ys)\n",
    "    y2 = max(Ys)\n",
    "    hight = y2 - y1\n",
    "    width = x2 - x1\n",
    "    if y1 < 0:\n",
    "        y1 = 0\n",
    "    if x1 < 0:\n",
    "        x1 = 0\n",
    "    if y1 + hight > size[0]:\n",
    "        hight = size[0] - y1\n",
    "    if x1 + width > size[1]:\n",
    "        width = size[1] - x1 \n",
    "    cropImg = image[y1:y1+hight, x1:x1+width]\n",
    "    #cv2.imwrite('cropimg.png', cropImg)\n",
    "    return cropImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gothrough(filepath,filepathset):\n",
    "    filenamelist = os.listdir(filepath)\n",
    "    #print(filenamelist)\n",
    "    for filename in filenamelist:\n",
    "        cur_filepath = os.sep.join([filepath, filename])\n",
    "    #     print(cur_filepath)\n",
    "        if os.path.isdir(cur_filepath):\n",
    "            gothrough(cur_filepath,filepathset)\n",
    "        else:\n",
    "            filepathset.append(filepath)\n",
    "            break\n",
    "    return filepathset     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)\n",
    "    filepathset = []\n",
    "    \n",
    "    filepathset = gothrough(INPUT_DIR, filepathset)\n",
    "    \n",
    "    for filepath in filepathset:\n",
    "        filelist = os.listdir(filepath)\n",
    "        for filename in filelist:\n",
    "            cur_filepath = os.path.join(filepath, filename) \n",
    "            cropImg = crop_pic(cur_filepath)\n",
    "            cv2.imwrite(OUTPUT_DIR + '\\\\' + filename, cropImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 2128, 3)\n",
      "85 1963 131 2005\n",
      "85 1963 131 1997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'AAaa0007005ac01b.jpg'\n",
    "filepath = r'D:\\Project\\jupyter\\demo\\learntemp'\n",
    "#step1：加载图片，转成灰度图\n",
    "image = cv2.imread(filename)\n",
    "#print(filename, image)\n",
    "size = image.shape\n",
    "print(size)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# print(gray)\n",
    "# cv.namedWindow('image', cv.WINDOW_NORMAL)\n",
    "# cv.imshow('image', image)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "# cv.imwrite('messigray.png',gray)\n",
    "#step2:用Sobel算子计算x，y方向上的梯度，之后在x方向上减去y方向上的梯度，通过这个减法，我们留下具有高水平梯度和低垂直梯度的图像区域。\n",
    "gradX = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "gradY = cv2.Sobel(gray, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "\n",
    "# subtract the y-gradient from the x-gradient\n",
    "gradient = cv2.subtract(gradX, gradY)\n",
    "gradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "#step3：去除图像上的噪声。首先使用低通滤泼器平滑图像（9 x 9内核）,这将有助于平滑图像中的高频噪声。\n",
    "#低通滤波器的目标是降低图像的变化率。如将每个像素替换为该像素周围像素的均值。这样就可以平滑并替代那些强度变化明显的区域。\n",
    "#然后，对模糊图像二值化。梯度图像中不大于90的任何像素都设置为0（黑色）。 否则，像素设置为255（白色）。\n",
    "# blur and threshold the image\n",
    "blurred = cv2.blur(gradient, (9, 9))\n",
    "(_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "#step4:在上图中我们看到蜜蜂身体区域有很多黑色的空余，我们要用白色填充这些空余，\n",
    "#使得后面的程序更容易识别昆虫区域，这需要做一些形态学方面的操作。\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#step5:从上图我们发现图像上还有一些小的白色斑点，这会干扰之后的昆虫轮廓的检测，要把它们去掉。分别执行4次形态学腐蚀与膨胀。\n",
    "# perform a series of erosions and dilations\n",
    "closed = cv2.erode(closed, None, iterations=4)\n",
    "closed = cv2.dilate(closed, None, iterations=4)\n",
    "\n",
    "# step6：找出昆虫区域的轮廓。cv2.findContours()函数第一个参数是要检索的图片，必须是为二值图，即黑白的（不是灰度图），\n",
    "#所以读取的图像要先转成灰度的，再转成二值图，我们在第三步用cv2.threshold()函数已经得到了二值图。第二个参数表示轮廓的检索模式，有四种：\n",
    "\n",
    "# cv2.RETR_EXTERNAL表示只检测外轮廓\n",
    "# cv2.RETR_LIST检测的轮廓不建立等级关系\n",
    "# cv2.RETR_CCOMP建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。\n",
    "# cv2.RETR_TREE建立一个等级树结构的轮廓。\n",
    "# 第三个参数为轮廓的近似方法\n",
    "\n",
    "# cv2.CHAIN_APPROX_NONE存储所有的轮廓点，相邻的两个点的像素位置差不超过1，即max（abs（x1-x2），abs（y2-y1））==1\n",
    "# cv2.CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息\n",
    "# cv2.findContours()函数返回两个值，一个是轮廓本身，还有一个是每条轮廓对应的属性。cv2.findContours()函数返回第一个值是list，\n",
    "#list中每个元素都是图像中的一个轮廓，用numpy中的ndarray表示。每一个ndarray里保存的是轮廓上的各个点的坐标。我们把list排序，\n",
    "#点最多的那个轮廓就是我们要找的昆虫的轮廓。 \n",
    "# OpenCV中通过cv2.drawContours在图像上绘制轮廓。\n",
    "\n",
    "# 第一个参数是指明在哪幅图像上绘制轮廓\n",
    "# 第二个参数是轮廓本身，在Python中是一个list\n",
    "# 第三个参数指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓\n",
    "# 第四个参数是轮廓线条的颜色\n",
    "# 第五个参数是轮廓线条的粗细\n",
    "# cv2.minAreaRect()函数: \n",
    "# 主要求得包含点集最小面积的矩形，这个矩形是可以有偏转角度的，可以与图像的边界不平行。\n",
    "\n",
    "#(cnts, _) = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "(_, cnts, whatever1)= cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# print(len(ans))\n",
    "# print(ans[0])\n",
    "# print(ans[1])\n",
    "# print(ans[2])\n",
    "c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]\n",
    "\n",
    "# compute the rotated bounding box of the largest contour\n",
    "rect = cv2.minAreaRect(c)\n",
    "box = np.int0(cv2.boxPoints(rect))\n",
    "\n",
    "# draw a bounding box arounded the detected barcode and display the image\n",
    "cv2.drawContours(image, [box], -1, (0, 255, 0), 3)\n",
    "#cv2.imshow(\"Image\", image)\n",
    "cv2.imwrite(\"contoursImage2.jpg\", image)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# step7：裁剪。box里保存的是绿色矩形区域四个顶点的坐标。我将按下图红色矩形所示裁剪昆虫图像。\n",
    "# 找出四个顶点的x，y坐标的最大最小值。新图像的高=maxY-minY，宽=maxX-minX。 \n",
    "Xs = [i[0] for i in box]\n",
    "Ys = [i[1] for i in box]\n",
    "x1 = min(Xs)\n",
    "x2 = max(Xs)\n",
    "y1 = min(Ys)\n",
    "y2 = max(Ys)\n",
    "hight = y2 - y1\n",
    "width = x2 - x1\n",
    "print(y1, hight, x1, width)\n",
    "if y1 < 0:\n",
    "    y1 = 0\n",
    "if x1 < 0:\n",
    "    x1 = 0\n",
    "if y1 + hight > size[0]:\n",
    "    hight = size[0] - y1\n",
    "if x1 + width > size[1]:\n",
    "    width = size[1] - x1 \n",
    "print(y1, hight, x1, width)\n",
    "cropImg = image[y1:y1+hight, x1:x1+width]\n",
    "cv2.imwrite('cropimg.png', cropImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
